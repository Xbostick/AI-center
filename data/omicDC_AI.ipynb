{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1768050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import stat\n",
    "import time\n",
    "import wget\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import progress\n",
    "import gc\n",
    "\n",
    "import multiprocessing\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from joblib import Parallel, delayed, load, dump\n",
    "\n",
    "\n",
    "#defines\n",
    "\n",
    "PRIVATE_PATH = \"/home/avoitetskii/private_omicON.txt\"\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "\n",
    "def create_matching_expirement_df(\n",
    "            que, \n",
    "            filename, \n",
    "            options\n",
    "        ):   \n",
    "    \"\"\" Function to return expirement names list\"\"\"\n",
    "\n",
    "    # match_exp_df - df for matching experiments\n",
    "    match_exp_df = pd.read_csv(\n",
    "                    FILE_PATH + filename,\n",
    "                    sep = '\\t', \n",
    "                    names = ['id', 'Genome assembly', 'Antigen class', 'Antigen', 'Cell type class', 'Cell type'],\n",
    "                    usecols=range(6)\n",
    "                )\n",
    "    if args.verbose:\n",
    "        print(\"Find file \" +  FILE_PATH + filename)\n",
    "\n",
    "    for key in options.keys():\n",
    "        if options[key]:\n",
    "            tmp = options[key].split(',')\n",
    "            match_exp_df = match_exp_df.loc[match_exp_df[key].isin(tmp)]\n",
    "\n",
    "    return match_exp_df\n",
    "\n",
    "\n",
    "def add_user_bed_markers(\n",
    "        que,\n",
    "        filename\n",
    "    ):\n",
    "    \"\"\" Merging sorted df with user`s .bed file as two additional cols\n",
    "        Saving onli rows with several chr.\n",
    "        Creating new 'intersect' column with booleans.\n",
    "        Returning df with only intersected\"\"\"\n",
    "    path_2_sorted_file_with_user_bed = FILE_PATH + \"filtred_and_bed\" + filename + \".csv\"\n",
    "\n",
    "    df = dd.read_csv(\n",
    "        FILE_PATH + \"filtred_\" + filename + \".csv\", \n",
    "        header=None, \n",
    "        sep=',',\n",
    "        names = ['chr', 'begin', 'end', 'id', 'score'],\n",
    "        blocksize = '10mb'\n",
    "        )\n",
    "    \n",
    "    process_list = []\n",
    "    \n",
    "    df.set_index('chr')\n",
    "\n",
    "    for part in range(df.npartitions):\n",
    "        process_list.append(que.submit(\n",
    "                                make_intersect,\n",
    "                                df,\n",
    "                                part,\n",
    "                                path_2_sorted_file_with_user_bed\n",
    "                                )) \n",
    "    \n",
    "    a = [process.result() for process in process_list]\n",
    "\n",
    "    return df.compute()\n",
    "\n",
    "\n",
    "def add_sorted_bed_2_file( \n",
    "            filename,\n",
    "            df,\n",
    "            num,\n",
    "            matching_experiments,\n",
    "        ):\n",
    "    \"\"\" Function to add lines to .csv file from part of sorted .bed files\"\"\"\n",
    "    part = df.partitions[num]\n",
    "    part = part.loc[part['id'].isin(matching_experiments)]\n",
    "    part = part.compute()\n",
    "    part.to_csv(filename, index=False, header=False, mode='a')\n",
    "    return num\n",
    "\n",
    "\n",
    "def create_sorted_bed_file(\n",
    "        que,\n",
    "        filename,\n",
    "        match_exp_df\n",
    "    ):\n",
    "    \"\"\"Create big .csv table with every finded match\"\"\"\n",
    "\n",
    "    path_2_sorted_file = FILE_PATH + \"filtred_\" + filename + \".csv\"\n",
    "\n",
    "    process_list = []\n",
    "\n",
    "    matching_experiments = list(match_exp_df.loc[:,'id'])\n",
    "\n",
    "    df = dd.read_csv(   \n",
    "                FILE_PATH + filename,\n",
    "                sep = \"\\t\", \n",
    "                names = ['chr', 'begin', 'end', 'id', 'score'],\n",
    "                blocksize = '50mb'\n",
    "                )\n",
    "\n",
    "    open(path_2_sorted_file, mode = 'w').close()  # Creating empty .csv for editing\n",
    "    os.chmod(path_2_sorted_file, 33279)\n",
    "\n",
    "    for part in range(df.npartitions):\n",
    "        process_list.append(que.submit(\n",
    "                                add_sorted_bed_2_file,\n",
    "                                path_2_sorted_file,\n",
    "                                df,\n",
    "                                part,\n",
    "                                matching_experiments\n",
    "                                ))\n",
    "    \n",
    "    a = [process.result() for process in process_list]\n",
    "    progress(a, notebook = False)\n",
    "\n",
    "\n",
    "def parse_private():\n",
    "    \"\"\"Function to take data from private .txt file\"\"\"\n",
    "    d = {}\n",
    "    with open(PRIVATE_PATH) as f:\n",
    "        for line in f:\n",
    "            if str(line) == '___Doc_list___\\n':\n",
    "                if args.verbose:\n",
    "                    print('___Doc_list___')\n",
    "                continue\n",
    "            (key, val) = line.split()\n",
    "            d[str(key)] = val\n",
    "\n",
    "            if args.verbose:\n",
    "                print(key, ':', val)\n",
    "    return(d)\n",
    "\n",
    "\n",
    "def omics(expid: str, assembly: str, assembly_threshold: str = '05', antigen_class: str, antigen: str, cell_type: str, cell: str, storage: Path):   \n",
    "    hyperparametrs = parse_private()\n",
    "    \n",
    "    NCORES    = int(hyperparametrs[\"NCORES\"])\n",
    "    NWORKERS  = int(hyperparametrs[\"NWORKERS\"])\n",
    "    IP        = hyperparametrs[\"IP\"]\n",
    "    PORT      = hyperparametrs[\"PORT\"]\n",
    "    FILE_PATH = hyperparametrs[\"file_path\"]\n",
    "\n",
    "    if not os.path.isfile(FILE_PATH + f'/allPeaks_light.{assembly}.{assembly_threshold}.bed')\n",
    "        wget.download(\n",
    "                        f'https://chip-atlas.dbcls.jp/data/hg38/allPeaks_light/\\\n",
    "                        allPeaks_light.{assembly}.{assembly_threshold}.bed.gz',\n",
    "                        FILE_PATH\n",
    "                      )\n",
    "        os.system(f\"gunzip {FILE_PATH}/allPeaks_light.{assembly}.{assembly_threshold}.bed.gz\")\n",
    "        \n",
    "    \n",
    "    options = {\n",
    "        #Parse arguments from cmd line to special dict\n",
    "        \"id\"                :   expid,\n",
    "        \"Genome assembly\"   :   assembly,\n",
    "        \"Antigen class\"     :   antigen_class,\n",
    "        \"Antigen\"           :   antigen,\n",
    "        \"Cell type class\"   :   cell_type,\n",
    "        \"Cell type\"         :   cell\n",
    "    }\n",
    "\n",
    "    for key in options.keys():\n",
    "        if options[key]:\n",
    "            options[key] = options[key].replace('_', ' ')\n",
    "\n",
    "    match_exp_df = create_matching_expirement_df(que, \"experimentList.tab\", options)\n",
    "\n",
    "    create_sorted_bed_file(que, hyperparametrs[assembly], match_exp_df)\n",
    "    que.shutdown()\n",
    "    \n",
    "    match_exp_df.to_csv(\n",
    "                        \"result.csv.gz\", \n",
    "                        index=False, \n",
    "                        compression=\"gzip\"\n",
    "                        )\n",
    "    \n",
    "    os.remove(FILE_PATH + \"filtred_\" + hyperparametrs[assembly] + \".csv\")\n",
    "\n",
    "\n",
    "def assembly(tag: str, saveto: Path, *_, force: bool = False):\n",
    "    supported = {\"GRCh38\", \"GRCm39\"}\n",
    "    assert tag in supported, f\"Requested assembly ({tag}) is not among supported: {','.join(supported)}\"\n",
    "\n",
    "    # TODO: clearer error message\n",
    "    assert saveto.name.endswith(\".gz\"), \"Loaded assemblies must be saved as indexed & bgzip-ed files\"\n",
    "\n",
    "    # Use GENCODE:\n",
    "    # After downloading, unzip -> bgzip -> samtools faidx files\n",
    "    # GRCh38 - https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/GRCh38.primary_assembly.genome.fa.gz\n",
    "    # GRCm39 - https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M32/GRCm39.primary_assembly.genome.fa.gz\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "__all__ = [\"omics\", \"assembly\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a539d088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
